{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Reinforcement Learning笔记1-MDP\n",
    "lang: zh\n",
    "date: 2017-11-11 18:18:56\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 马尔可夫模型介绍（Markov）\n",
    "\n",
    "马尔可夫模型的几类子模型:\n",
    "\n",
    "| 　             |      不考虑动作     |               考虑动作              |\n",
    "|----------------|:-------------------:|:-----------------------------------:|\n",
    "| 状态完全可见   | 马尔科夫链(MC)      | 马尔可夫决策过程(MDP)               |\n",
    "| 状态不完全可见 | 隐马尔可夫模型(HMM) | 不完全可观察马尔可夫决策过程(POMDP) |\n",
    "\n",
    "- Markdown table - [tablesgenerator](http://www.tablesgenerator.com/markdown_tables \"Title\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 马尔可夫决策过程（MDP）\n",
    "\n",
    "马尔可夫决策过程（Markov Decision Processes, MDP）简单说就是一个智能体（Agent）采取行动（Action）从而改变自己的状态（State）获得奖励（Reward）与环境（Environment）发生交互的循环过程。\n",
    "\n",
    "MDP 的策略完全取决于当前状态（Only present matters），可以简单表示为： \n",
    "\n",
    "\\begin{align}    \n",
    "M = <S, A, P_{s,a}, R>\n",
    "\\end{align}\n",
    " \n",
    " ① $s \\in S$: 有限状态 state 集合，s 表示某个特定状态\n",
    " \n",
    " ② $a \\in A$: 有限动作 action 集合，a 表示某个特定动作\n",
    " \n",
    " ③ Transition Model $T(S, a, S') \\sim P_r(s'|s, a)$: Transition Model, 根据当前状态 s 和动作 a 预测下一个状态 $s’$，这里的 $P_r$ 表示从 s 采取行动 a 转移到 $s’$ 的概率\n",
    " \n",
    " ④ Reward $R(s, a) = E[R_{t+1}|s, a]$:表示 agent 采取某个动作后的即时奖励，它还有 R(s, a, s’), R(s) 等表现形式，采用不同的形式，其意义略有不同\n",
    " \n",
    " ⑤ Policy $\\pi(s) \\to a$: 根据当前 state 来产生 action，可表现为 $a=\\pi(s)$ 或 $\\pi(a|s) = P[a|s]$，后者表示某种状态下执行某个动作的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MDP 求解\n",
    "\n",
    "需要找到最优的策略使未来回报最大化，求解过程大致可分为两步：\n",
    "\n",
    " ① 预测：给定策略，评估相应的状态价值函数和状态-动作价值函数\n",
    " \n",
    " ② 行动：根据价值函数得到当前状态对应的最优动作\n",
    "\n",
    "- 推荐课程 - [CS 294: Deep Reinforcement Learning](http://rll.berkeley.edu/deeprlcourse/ \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 参考资料（Reference）\n",
    "\n",
    "- [Pythonではじめる強化学習](https://qiita.com/Hironsan/items/56f6c0b2f4cfd28dd906 \"Title\") \n",
    "\n",
    "- [ゼロからDeepまで学ぶ強化学習](https://qiita.com/icoxfog417/items/242439ecd1a477ece312 \"Title\") \n",
    "\n",
    "- [强化学习知识整理](https://zhuanlan.zhihu.com/p/25319023?utm_source=tuicool&utm_medium=referral \"Title\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
